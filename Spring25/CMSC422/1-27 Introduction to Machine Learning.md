## Importance
- Big data and the abundance of availability.
- Machine intelligence.
## Large Language Models
- Future impact may be even greater.
- Affects our view of intelligence.
- Trained with trillions of words.
- A major goal of this class is to explain how LLMs work.
### Applications
- Autonomous vehicles.
- Machine translation.
- Speech recognition.
- Recommendation engines.
- Visual recognition.
- Protein folding (figuring out the 3D structure of proteins).
## Big Data
- The availability of large digital datasets is transformative.
- Three enabling technologies:
	- Data digitization.
	- Internet.
	- Faster computers with more memory.
# What is Machine Learning?
- Giving "computers the ability to learn without being explicitly programmed".
- Something about using data, finding patterns and features in data, using these to solve tasks better and better as more data is available.
## Supervised vs Unsupervised
- Both have data.
- Supervision means that we have training data that is _labeled_ with a desired output.
	- Later, _test_ data will not have labels. We want to learn to infer them.
- Unsupervised means we train _without labels_.
- Self-supervised means labels come from the data itself.
### Unsupervised
- Dimensionality reduction
	- Visualization, preprocessing.
- Clustering
	- Discovery of communities, species, ...
- Anomaly detection
	- Fraud
- Pattern discovery
## Machine vs Biological Learning
- ML is not necessarily what we colloquially think of as _learning_.
	- Learning the periodic tables is memorization.
	- Many problems ML soles are solved by evolution in biology.
- Many differences in conditions of learning.
	- Biological learning usually leverages a lot of background knowledge.
	- Labeled data isn't common in biology.
- 