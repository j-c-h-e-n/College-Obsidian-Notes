- The field of AI "is concerned with not just understanding but also *building* intelligent entities - machines that can compute how to act effectively and safely in a wide variety of novel situations".
## 1.1 What Is AI?
- "Some AI systems use machine learning methods to achieve competence, but some do not".
- Research in two dimensions: human vs rational and thought vs behavior.
### 1.1.1 Acting humanly: The Turing test approach
- To pass the Turing test (Alan Turing 1950), a computer had to have:
	- NLP to communicate successfully in a human language.
	- Knowledge representation to store what it knows or hears.
	- Automated reasoning to answer questions and to draw new conclusions.
	- Machine learning to adapt to new circumstances and to detect and extrapolate patterns.
- Other researchers proposed a **total Turing test**. Adding on two more requirements:
	- Computer vision and speech recognition to perceive the world.
	- Robotics to manipulate objects and move about.
### 1.1.2 Thinking humanly: The cognitive modeling approach
- Three ways to learn about human thought:
	- Introspection: trying to catch our own thoughts as they go by.
	- Psychological experiments: observing a person in action.
	- Brain imaging: observing the brain in action.
- After sufficient data, we can attempt to express our theories of the brain as a computer program.
- Neurological research and AI develop separately but in parallel, these two fields can shed further light in each other.
- Cognitive modeling approach.
### 1.1.3 Thinking rationally: The "laws of thought" approach
- Logicians in 19th century developed precise notation for statements about objects in the world and the relations between them.
- By 1965 programs could solve any *solvable* problem in logical notation.
- Logic conventionally requires knowledge that is **certain**. But the real world is not this way, the *theory of probability* serves to fill this gap, allowing logic with uncertain information.   
- This allows the generation of rational thought, but not behavior.
- Logics approach.
### 1.1.4 Acting rationally: The rational agent approach
- Agent: Something that acts.
- All computer programs do something, but computer *agents are expected to operate autonomously*. i.e. perceive their environment, persist over a prolonged time period, adapt to change, and create and pursue goals.
- A rational agent aims to achieve the best or best expected outcome.
	- Determine best action, then execute.
	- OR, act on reflex that does not need inference (recoiling from hot stove).
- All skills needed for the Turing test also fulfills the requirements for an Agent to be considered rational.
- Advantages over cognitive and and logics approach:
	- More general than the logics approach.
	- More amenable to scientific development due to the standard of rationality being mathematically well defined and completely general.
- Early rational agents were built on deterministic situations. Later agents based on probability theory and ML allowed decisions under uncertainty.
- The standard model: The "right thing" to do/achieve defined by the objective we provide to the agent.
### 1.1.5 Beneficial machines
- The standard model isn't the best for the long run since it assumes we have a fully specified objective.
- Standard model works with:
	- Chess.
	- Shortest-path.
- Doesn't work with:
	- Autonomous driving where anything can happen between destinations.
	- Human-robot interaction intersections.
- Value Alignment Problem: The trouble of achieving agreement between our human true preferences and the objective we feed to the machine. The objectives we provide must be aligned with those of the human.
	- Systems deployed in the real world with the incorrect, non-human aligned objectives will have negative consequences.
	- Smart chess machines may go beyond the chess board - attempts to hypnotizing, blackmailing, etc. opponents to achieve victory no matter what.
	- Attempts to use the standard model in more advanced machines will result in too many loose ends. We need machines to pursue *our* objectives, not *their* objectives.

## 1.2 Foundations of AI
- Brief history of disciplines that contributed ideas, viewpoints, and techniques to AI.
### 1.2.1 Philosophy
- Questions to consider:
	- Can formal rules be used to draw valid conclusions?
	- How does the mind arise from a physical brain?
	- Where does knowledge come from?
	- How does knowledge lead to action?
- Dualism: "If the mind were entirely governed by physical laws, then there would be no room for free will". Claimed animals were not subject, therefore could be treated as machines as opposed to the free willed humans.
- Alternative to dualism is materialism, state that the mind is the result of the brain's operation under the laws of physics.
	- Physicalism and naturalism are synonyms to materialism.
- Now, modern AI adopt the approach of deontological ethics, rule-based, which highlights the idea of "doing the right thing" as not classified by the outcomes, but by universal social laws that govern allowable actions (i.e. not killing, not lying, etc).
### 1.2.2 Mathematics
- Questions to consider:
	- What are the formal rules to draw valid conclusions?
	- What can be computed?
	- How do we reason with uncertain information?
- Formal logic is formed on the basis of propositional/Boolean logic. Then expanded with objects and relations, resulting in the first-order logic used today. (think of the logical statements learned in Discrete Math, and often used in proof language).
- Theory of probability dealt with the computation of uncertain situations (gambling, percentages, probabilities) that became a way to deal with uncertain measurements and incomplete theories. Jacob Bernoulli, Pierre Laplace, Thomas Bayes, etc.
	- Baye's rule is critical to AI.
- The first non-trivial algorithm is thought to be Euclid's alg for GCD.
- Tractability:
	- A problem is intractable if the time required to solve instances of the problem grows exponentially with the size of the instances.
	- Exponential and polynomial growth was emphasized where moderately large instances of problems with exponential growth cannot be solved in any reasonable time.
- NP-Completeness (Non-deterministic Polynomial):
	- Any problem class to which the class of NP-complete problems can be reduced is likely to be intractable.
	- Problems that are solvable in exponential time and verifiable in polynomial time.
	- It has not been proved that NP-complete problems are necessarily intractable.
### 1.2.3 Economics
- Questions to consider:
	- How should we make decisions in accordance with our preferences?
	- How should we do this when others may not go along?
	- How should we do this when the payoff may be far in the future?
- Decision theory combined probability theory with utility theory, providing a formal and complete framework for individual decisions (economic or otherwise) made under uncertainty.
	- Suitable for "large" economies where each agent don't need to pay attention to the actions of other agents as individuals.
	- "You vs nature/uncertainty".
- Game theory introduced a surprising result that sometimes a rational agent should adopt policies with randomization.
- Unlike decision theory, game theory doesn't offer an unambiguous prescription for selection actions.
	- "You vs other players".
- In AI, decisions involving multiple agents are studied under the heading of multiagent systems.
- Sequential decision problems (where payoffs aren't reaped immediately, but rather in the future after several turns) are modeled with Markov Decision Processes.
- There has been a resurgence of making models that make "good enough" decisions over the optimal decision in favor of a more human-like decision process, as well as compute efficiency.
### 1.2.4 Neuroscience
-  Question:
	- How do brains process information?
- Neuroscience studies the nervous system, particularly the brain.
- The development of brain-machine interfaces allow the recovery of sensing and motor controls to patients while also accelerating understanding of our neural systems.
- Although computers have been accelerating at an exceptional rate, they still do not rival natural human brains. Ultimately, without the right theory, faster machines just give you the wrong answer faster.
### 1.2.5 Psychology
- Question:
	- How do humans and animals think and act?
- 